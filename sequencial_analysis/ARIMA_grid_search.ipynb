{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA Grid Search\n",
    "\n",
    "I found a tutorial and I don't like it.\n",
    "So, finally decided to find an easier solution to do grid search for ARIMA, and to add cross validation in a way that's easier to understand.\n",
    "\n",
    "Download the data here (no need login):\n",
    "https://datamarket.com/data/set/22r0/sales-of-shampoo-over-a-three-year-period#!ds=22r0&display=line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Month\n",
       "1-01    266.0\n",
       "1-02    145.9\n",
       "1-03    183.1\n",
       "1-04    119.3\n",
       "1-05    180.3\n",
       "Name: Sales of shampoo over a three year period, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = pd.read_csv('shampoo_sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True)\n",
    "series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Month\n",
       "1901-01-01    266.0\n",
       "1901-02-01    145.9\n",
       "1901-03-01    183.1\n",
       "1901-04-01    119.3\n",
       "1901-05-01    180.3\n",
       "Name: Sales of shampoo over a three year period, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parser(x):\n",
    "    return pd.datetime.strptime('190'+x, '%Y-%m')\n",
    "\n",
    "series = pd.read_csv('shampoo_sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([266. , 145.9, 183.1, 119.3, 180.3, 168.5, 231.8, 224.5, 192.8,\n",
       "       122.9, 336.5, 185.9, 194.3, 149.5, 210.1, 273.3, 191.4, 287. ,\n",
       "       226. , 303.6, 289.9, 421.6, 264.5, 342.3, 339.7, 440.4, 315.9,\n",
       "       439.3, 401.3, 437.4, 575.5, 407.6, 682. , 475.3, 581.3, 646.9])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best AIC and order are: 355.5008750421533 (1, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "# Method 1 - Without cross validation, just simply grid search for ARIMA\n",
    "p = d = q = range(0, 3)\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "bestAIC = np.inf\n",
    "bestParam = None\n",
    "\n",
    "# grid search\n",
    "for param in pdq:\n",
    "    try:\n",
    "        model = sm.tsa.statespace.SARIMAX(series.values,\n",
    "                                          order=param,\n",
    "                                          enforce_stationarity=False,\n",
    "                                          enforce_invertibility=False)\n",
    "        results = model.fit()\n",
    "        #if current run of AIC is better than the best one so far, overwrite it\n",
    "        if results.aic < bestAIC:\n",
    "            bestAIC = results.aic\n",
    "            bestParam = param\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "print('the best AIC and order are:',bestAIC,bestParam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [0 1 2 3 4 5] TEST: [6 7 8]\n",
      "TRAIN: [0 1 2 3 4 5 6 7 8] TEST: [ 9 10 11]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11] TEST: [12 13 14]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] TEST: [15 16 17]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17] TEST: [18 19 20]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20] TEST: [21 22 23]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23] TEST: [24 25 26]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26] TEST: [27 28 29]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29] TEST: [30 31 32]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32] TEST: [33 34 35]\n"
     ]
    }
   ],
   "source": [
    "# Method 2 - Add cross validation with grid search for ARIMA\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "for train_index, test_index in tscv.split(series.values):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best AIC, the best CV AIC and order are: 33.19568230991611 inf (0, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "p = d = q = range(0, 3)\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "bestAIC = np.inf\n",
    "best_cvAIC = np.inf\n",
    "bestParam = None\n",
    "best_cvParam = None\n",
    "\n",
    "X = series.values\n",
    "\n",
    "# grid search\n",
    "for param in pdq:\n",
    "    for train_index, test_index in tscv.split(series.values):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        try:\n",
    "            model = sm.tsa.statespace.SARIMAX(X_train,\n",
    "                                              order=param,\n",
    "                                              enforce_stationarity=False,\n",
    "                                              enforce_invertibility=False)\n",
    "            results = model.fit()\n",
    "            #if current run of AIC is better than the best one so far, overwrite it\n",
    "            if results.aic < bestAIC:\n",
    "                bestAIC = results.aic\n",
    "                bestParam = param\n",
    "\n",
    "            # apply the best order on testig data\n",
    "            best_model = sm.tsa.statespace.SARIMAX(X_test,\n",
    "                                              order=bestParam,\n",
    "                                              enforce_stationarity=False,\n",
    "                                              enforce_invertibility=False)\n",
    "            results = best_smodel.fit()\n",
    "            if results.aic < best_cvAIC:\n",
    "                best_cvAIC = results.aic\n",
    "                best_cvParam = bestParam\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "print('the best AIC, the best CV AIC and order are:',bestAIC,best_cvAIC,bestParam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "* https://machinelearningmastery.com/grid-search-arima-hyperparameters-with-python/\n",
    "  * I don't like this one, it implemented everything while there are libraries to use. I think the beauty of python is you have many existing libraries to use, why build your own when there are better choices? With so much time you can do many other things...\n",
    "* https://www.kaggle.com/sbongo/another-look-at-forecasting-gridsearch-arima\n",
    "  * This is a much better one\n",
    "* https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html\n",
    "  * About `SARIMAX` model\n",
    "  * About statesapce: https://www.statsmodels.org/dev/statespace.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
